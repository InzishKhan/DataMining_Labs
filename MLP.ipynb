{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nxg3K6THjGyG",
        "outputId": "eec2888e-4902-4f89-9428-5c05b0f917ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final weights for AND Gate : [5.61665485 5.61060231]\n",
            "Final bias for AND Gate : -8.588678182412002\n",
            "Final weights for OR Gate : [6.81165138 6.81524057]\n",
            "Final bias for OR Gate : -2.9282891743610717\n",
            "\n",
            "Testing the trained perceptron on AND gate inputs:\n",
            "Inputs: [0 0], Predicted Output: 0\n",
            "Inputs: [0 1], Predicted Output: 0\n",
            "Inputs: [1 0], Predicted Output: 0\n",
            "Inputs: [1 1], Predicted Output: 1\n",
            "\n",
            "Testing the trained perceptron on OR gate inputs:\n",
            "Inputs: [0 0], Predicted Output: 0\n",
            "Inputs: [0 1], Predicted Output: 1\n",
            "Inputs: [1 0], Predicted Output: 1\n",
            "Inputs: [1 1], Predicted Output: 1\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "Initial_weights = [1.0, 1.0]\n",
        "Initial_bias = 1.0\n",
        "learning_rate=0.1\n",
        "max_iterations=1000\n",
        "# Defining the sigmoid activation function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Perceptron learning algorithm\n",
        "def perceptron_learning(inputs, labels, initial_weights, initial_bias):\n",
        "    # Initialize weights and bias\n",
        "    weights = np.array(initial_weights)\n",
        "    bias = initial_bias\n",
        "\n",
        "    # Initialize convergence flag\n",
        "    converge = False\n",
        "    iterations = 0\n",
        "\n",
        "    while not converge and iterations < max_iterations:\n",
        "        converge = True\n",
        "\n",
        "        for input, label in zip(inputs, labels):\n",
        "            # Computing the z summation value\n",
        "            zsum = np.dot(input, weights) + bias\n",
        "\n",
        "            # computing ypred using the sigmoid activation function\n",
        "            ypred = sigmoid(zsum)\n",
        "\n",
        "            # Updating weights if actual is not equal to predicted\n",
        "            if ypred != label:\n",
        "                converge = False\n",
        "                #updating weights\n",
        "                weights += learning_rate * (label - ypred) * input\n",
        "                #updating bias\n",
        "                bias += learning_rate * (label - ypred)\n",
        "\n",
        "        iterations += 1\n",
        "\n",
        "    return weights, bias\n",
        "\n",
        "# AND Gate Perceptron Learning\n",
        "ANDInput = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "ANDLabels = np.array([0, 0, 0, 1])\n",
        "# Learning Weights that will provide the correct classification\n",
        "finalANDweights, finalANDbias = perceptron_learning(ANDInput, ANDLabels, Initial_weights, Initial_bias)\n",
        "print(\"Final weights for AND Gate :\", finalANDweights)\n",
        "print(\"Final bias for AND Gate :\", finalANDbias)\n",
        "\n",
        "# OR Gate   Perceptron Learning\n",
        "ORInput = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "ORLabels = np.array([0, 1, 1, 1])\n",
        "# Perceptron Learning in accordance with 'OR GATE'\n",
        "finalORweights, finalORbias = perceptron_learning(ORInput, ORLabels, Initial_weights, Initial_bias)\n",
        "#output for the learned weights for the correctly classifying ypredicted\n",
        "print(\"Final weights for OR Gate :\", finalORweights)\n",
        "print(\"Final bias for OR Gate :\", finalORbias)\n",
        "\n",
        "# Testing AND gate perceptron\n",
        "print(\"\\nTesting the trained perceptron on AND gate inputs:\")\n",
        "for inputs in ANDInput:\n",
        "    zsum = np.dot(inputs, finalANDweights) + finalANDbias\n",
        "    ypred = sigmoid(zsum)\n",
        "    # Modify predicted output based on threshold\n",
        "    if ypred > 0.5:\n",
        "        ypred = 1\n",
        "    else:\n",
        "        ypred = 0\n",
        "    print(f\"Inputs: {inputs}, Predicted Output: {ypred}\")\n",
        "\n",
        "\n",
        "print(\"\\nTesting the trained perceptron on OR gate inputs:\")\n",
        "\n",
        "for inputs in ORInput:\n",
        "    zsum = np.dot(inputs, finalORweights) + finalORbias\n",
        "    ypred = sigmoid(zsum)\n",
        "    # Modify predicted output based on threshold\n",
        "    if ypred > 0.5:\n",
        "        ypred = 1\n",
        "    else:\n",
        "        ypred = 0\n",
        "    print(f\"Inputs: {inputs}, Predicted Output: {ypred}\")\n"
      ]
    }
  ]
}